{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cdc-2021-03-31_10_30_32\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "## Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.logger_v1 import setup_logs\n",
    "# from src.data_reader.dataset import RawDataset, ReverseRawDataset, RawXXreverseDataset\n",
    "# from src.training_v1 import trainXXreverse, snapshot\n",
    "# from src.validation_v1 import validationXXreverse\n",
    "# from src.model.model import CDCK5, CDCK6\n",
    "############ Control Center and Hyperparameter ###############\n",
    "run_name = \"cdc\" + time.strftime(\"-%Y-%m-%d_%H_%M_%S\")\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    shape =  (a.shape[0] - window + 1, window) + a.shape[1:]\n",
    "    strides = (a.strides[0],) + a.strides\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides, writeable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledOptim(object):\n",
    "    \"\"\"A simple wrapper class for learning rate scheduling\"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, n_warmup_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = 128 \n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0 \n",
    "        self.delta = 1\n",
    "\n",
    "    def state_dict(self):\n",
    "        self.optimizer.state_dict()\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Step by the inner optimizer\"\"\"\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Zero out the gradients by the inner optimizer\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def increase_delta(self):\n",
    "        self.delta *= 2\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        \"\"\"Learning rate scheduling per step\"\"\"\n",
    "\n",
    "        self.n_current_steps += self.delta\n",
    "        new_lr = np.power(self.d_model, -0.5) * np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "        return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TETrainDataset(data.Dataset):\n",
    "    def __init__(self, fault=list(range(1,21)), window=20):\n",
    "        \"\"\" fault: [1,2,3,4,5,6]\n",
    "            window: 20\n",
    "        \"\"\"\n",
    "        self.window = window \n",
    "        temp = torch.from_numpy(rolling_window(np.loadtxt('data/d00.dat').T, window))\n",
    "        self.sample = [temp]\n",
    "        self.label = [0 for _ in temp]\n",
    "\n",
    "        for label in fault:\n",
    "            if label < 10:\n",
    "                num = '0' + str(label)\n",
    "            else:\n",
    "                num = str(label)\n",
    "            temp = rolling_window(np.loadtxt('data/d' + num + '.dat'), window)\n",
    "            self.sample.append(temp)\n",
    "            self.label.extend([label for _ in temp])\n",
    "        \n",
    "        self.sample = np.concatenate(self.sample,0)\n",
    "        \n",
    "        if os.path.exists('./scalar'):\n",
    "            std = joblib.load('./scalar')\n",
    "            sh = self.sample.shape\n",
    "            self.sample = std.transform(self.sample.reshape(-1,sh[-1])).reshape(sh)\n",
    "        else:\n",
    "            std = StandardScaler()\n",
    "            sh = self.sample.shape\n",
    "            std.fit(self.sample.reshape(-1,sh[-1]))\n",
    "            self.sample = std.transform(self.sample.reshape(-1,sh[-1])).reshape(sh)\n",
    "            joblib.dump(std, './scalar')\n",
    "        \n",
    "        self.sample = torch.from_numpy(self.sample).float()\n",
    "        self.label = torch.tensor(self.label).float()\n",
    "        assert self.sample.shape[0] == self.label.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.sample[index], self.label[index]\n",
    "\n",
    "class TETestDataset(data.Dataset):\n",
    "    def __init__(self, fault=list(range(1,21)), window=20):\n",
    "        \"\"\" fault: [1,2,3,4,5,6]\n",
    "            window: 20\n",
    "        \"\"\"\n",
    "        self.window = window \n",
    "        temp = torch.from_numpy(rolling_window(np.loadtxt('data/d00_te.dat'), window))\n",
    "        self.sample = [temp]\n",
    "        self.label = [0 for _ in temp]\n",
    "\n",
    "        for label in fault:\n",
    "            if label < 10:\n",
    "                num = '0' + str(label)\n",
    "            else:\n",
    "                num = str(label)\n",
    "            temp = rolling_window(np.loadtxt('data/d' + num + '_te.dat'), window)\n",
    "            self.sample.append(temp)\n",
    "            if window <= 160:\n",
    "                self.label.extend([0 for _ in range(160-window+1)])\n",
    "                self.label.extend([label for _ in range(800)])\n",
    "            else:\n",
    "                self.label.extend([label for _ in range(960-window+1)])\n",
    "        \n",
    "        self.sample = np.concatenate(self.sample,0)\n",
    "        \n",
    "        if os.path.exists('./scalar'):\n",
    "            std = joblib.load('./scalar')\n",
    "            sh = self.sample.shape\n",
    "            self.sample = std.transform(self.sample.reshape(-1,sh[-1])).reshape(sh)\n",
    "        else:\n",
    "            std = StandardScaler()\n",
    "            sh = self.sample.shape\n",
    "            std.fit(self.sample.reshape(-1,sh[-1]))\n",
    "            self.sample = std.transform(self.sample.reshape(-1,sh[-1])).reshape(sh)\n",
    "            joblib.dump(std, './scalar')\n",
    "        \n",
    "        self.sample = torch.from_numpy(self.sample).float()\n",
    "        self.label = torch.tensor(self.label).float()\n",
    "        assert self.sample.shape[0] == self.label.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.sample[index], self.label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPC_GRU(nn.Module):\n",
    "    def __init__(self, input_size, low_size, high_size, num_layers, timestep, batch_size, seq_len):\n",
    "\n",
    "        super(CPC_GRU, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.timestep = timestep\n",
    "        self.input_size = input_size\n",
    "        self.low_size = low_size\n",
    "        self.high_size = high_size\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = nn.Sequential( # downsampling factor = 160\n",
    "            nn.Linear(self.input_size,self.low_size, bias=False),\n",
    "            nn.BatchNorm1d(self.seq_len+self.timestep),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.low_size, self.low_size, bias=False),\n",
    "            nn.BatchNorm1d(self.seq_len+self.timestep),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.gru = nn.GRU(self.low_size, self.high_size, num_layers=self.num_layers, bidirectional=False, batch_first=True)\n",
    "        self.Wk  = nn.ModuleList([nn.Linear(self.high_size, self.low_size) for i in range(timestep)])\n",
    "        self.softmax  = nn.Softmax()\n",
    "        self.lsoftmax = nn.LogSoftmax()\n",
    "\n",
    "        def _weights_init(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # initialize gru\n",
    "        for layer_p in self.gru._all_weights:\n",
    "            for p in layer_p:\n",
    "                if 'weight' in p:\n",
    "                    nn.init.kaiming_normal_(self.gru.__getattr__(p), mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def init_hidden(self, batch_size, use_gpu=True):\n",
    "        if use_gpu: return torch.zeros(self.num_layers, batch_size, self.high_size).cuda()\n",
    "        else: return torch.zeros(self.num_layers, batch_size, self.high_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch = x.size()[0]\n",
    "        # t_samples = torch.randint(self.seq_len/160-self.timestep, size=(1,)).long() # randomly pick time stamps\n",
    "        # input sequence is N*C*L, e.g. 8*1*20480\n",
    "        z = self.encoder(x)\n",
    "        # encoded sequence is N*C*L, e.g. 8*512*128\n",
    "        # reshape to N*L*C for GRU, e.g. 8*128*512\n",
    "        encode_samples = z[:,-1*self.timestep:,:].transpose(0,1)\n",
    "        # z = z.transpose(1,2)\n",
    "        nce = 0 # average over timestep and batch\n",
    "        # encode_samples = torch.empty((self.timestep,batch,512)).float() # e.g. size 12*8*512\n",
    "        # for i in np.arange(1, self.timestep+1):\n",
    "        #     encode_samples[i-1] = z[:,t_samples+i,:].view(batch,512) # z_tk e.g. size 8*512\n",
    "        forward_seq = z[:,:self.seq_len,:] # e.g. size 8*100*512\n",
    "        output, hidden = self.gru(forward_seq, hidden) # output size e.g. 8*100*256\n",
    "        c_t = output[:,-1,:].view(batch, -1) # c_t e.g. size 8*256\n",
    "        pred = torch.empty((self.timestep,batch,32)).float().to(x.device) # e.g. size 12*8*512\n",
    "        for i in np.arange(0, self.timestep):\n",
    "            pred[i] = self.Wk[i](c_t) # Wk*c_t e.g. size 8*512\n",
    "        for i in np.arange(0, self.timestep):\n",
    "            total = torch.mm(encode_samples[i], torch.transpose(pred[i],0,1)) # e.g. size 8*8\n",
    "            correct = torch.sum(torch.eq(torch.argmax(self.softmax(total), dim=0).cpu(), torch.arange(0, batch))) # correct is a tensor\n",
    "            nce += torch.sum(torch.diag(self.lsoftmax(total))) # nce is a tensor\n",
    "        nce /= -1.*batch*self.timestep\n",
    "        accuracy = 1.*correct.item()/batch\n",
    "\n",
    "        return accuracy, nce\n",
    "\n",
    "    def predict(self, x, hidden):\n",
    "        batch = x.size()[0]\n",
    "        # input sequence is N*C*L, e.g. 8*1*20480\n",
    "        z = self.encoder(x)\n",
    "        # encoded sequence is N*C*L, e.g. 8*512*128\n",
    "        # reshape to N*L*C for GRU, e.g. 8*128*512\n",
    "        z = z.transpose(1,2)\n",
    "        output, hidden = self.gru(z, hidden) # output size e.g. 8*128*256\n",
    "\n",
    "        return output, hidden # return every frame\n",
    "        #return output[:,-1,:], hidden # only return the last frame per utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch, batch_size):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        seq, label = data\n",
    "        seq, label = seq.to(device), label.to(device)\n",
    "        # seq = seq.to(device) # add channel dimension\n",
    "        optimizer.zero_grad()\n",
    "        hidden = model.init_hidden(len(seq), use_gpu=True)\n",
    "        acc, loss = model(seq, hidden)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr = optimizer.update_learning_rate()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            logger.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tlr:{:.5f}\\tAccuracy: {:.4f}\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), lr, acc, loss.item()))\n",
    "\n",
    "def validation(args, model, device, data_loader, batch_size):\n",
    "    logger.info(\"Starting Validation\")\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc  = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            seq, label = data\n",
    "            seq, label = seq.to(device), label.to(device)\n",
    "            # data = data.float().unsqueeze(1).to(device) # add channel dimension\n",
    "            hidden = model.init_hidden(len(seq), use_gpu=True)\n",
    "            acc, loss = model(seq, hidden)\n",
    "            total_loss += len(seq) * loss \n",
    "            total_acc  += len(seq) * acc\n",
    "\n",
    "    total_loss /= len(data_loader.dataset) # average loss\n",
    "    total_acc  /= len(data_loader.dataset) # average acc\n",
    "\n",
    "    logger.info('===> Validation set: Average loss: {:.4f}\\tAccuracy: {:.4f}\\n'.format(\n",
    "                total_loss, total_acc))\n",
    "\n",
    "    return total_acc, total_loss\n",
    "\n",
    "def snapshot(dir_path, run_name, state):\n",
    "    snapshot_file = os.path.join(dir_path,\n",
    "                    run_name + '-model_best.pth')\n",
    "    \n",
    "    torch.save(state, snapshot_file)\n",
    "    logger.info(\"Snapshot saved to {}\\n\".format(snapshot_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "use_cuda is True\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     ## Settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--train-raw', default='LibriSpeech/train-Librispeech.h5')\n",
    "parser.add_argument('--validation-raw', default='LibriSpeech/validation-Librispeech.h5')\n",
    "parser.add_argument('--eval-raw', default='LibriSpeech/eval-Librispeech.h5')\n",
    "parser.add_argument('--train-list', default='LibriSpeech/list/train.txt')\n",
    "parser.add_argument('--validation-list', default='LibriSpeech/list/validation.txt')\n",
    "parser.add_argument('--eval-list')\n",
    "parser.add_argument('--logging-dir', default='snapshot/cdc/',\n",
    "                    help='model save directory')\n",
    "parser.add_argument('--epochs', type=int, default=60, metavar='N',\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--n-warmup-steps', type=int, default=50)\n",
    "parser.add_argument('--batch-size', type=int, default=10, \n",
    "                    help='batch size')\n",
    "parser.add_argument('--window', type=int, default=20, \n",
    "                    help='window length to sample from each utterance')\n",
    "parser.add_argument('--timestep', type=int, default=10) \n",
    "parser.add_argument('--masked-frames', type=int, default=20)\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "#     args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print('use_cuda is', use_cuda)\n",
    "global_timer = timer() # global timer\n",
    "logger = setup_logs(args.logging_dir, run_name) # setup logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "===> loading train, validation and eval dataset\n",
      "===> loading train, validation and eval dataset\n",
      "### Model summary below###\n",
      " CPC_GRU(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=52, out_features=32, bias=False)\n",
      "    (1): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (4): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (gru): GRU(32, 16, num_layers=2, batch_first=True)\n",
      "  (Wk): ModuleList(\n",
      "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (4): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (5): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (6): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (7): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (8): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (9): Linear(in_features=16, out_features=32, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (lsoftmax): LogSoftmax(dim=None)\n",
      ")\n",
      "\n",
      "### Model summary below###\n",
      " CPC_GRU(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=52, out_features=32, bias=False)\n",
      "    (1): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (4): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (gru): GRU(32, 16, num_layers=2, batch_first=True)\n",
      "  (Wk): ModuleList(\n",
      "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (4): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (5): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (6): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (7): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (8): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (9): Linear(in_features=16, out_features=32, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (lsoftmax): LogSoftmax(dim=None)\n",
      ")\n",
      "\n",
      "===> Model total parameter: 12280\n",
      "\n",
      "===> Model total parameter: 12280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# model = CPC(52, args.timestep, args.batch_size, args.window).to(device)\n",
    "model = CPC_GRU(input_size=52, low_size=32, high_size=16, num_layers=2, timestep=args.timestep, batch_size=args.batch_size, seq_len=args.window).to(device)\n",
    "#model = CDCK5(args.timestep, args.batch_size, args.audio_window).to(device)\n",
    "#model = CDCK6(args.timestep, args.batch_sz\n",
    "params = {'num_workers': 0,\n",
    "            'pin_memory': False} if use_cuda else {}\n",
    "\n",
    "logger.info('===> loading train, validation and eval dataset')\n",
    "training_set   = TETrainDataset(window=args.window+args.timestep)\n",
    "#training_set   = ReverseRawDataset(args.train_raw, args.train_list, args.audio_window)\n",
    "#training_set   = RawXXreverseDataset(args.train_raw, args.train_list, args.audio_window)\n",
    "test_set = TETestDataset(window=args.window+args.timestep)\n",
    "#validation_set = ReverseRawDataset(args.validation_raw, args.validation_list, args.audio_window)\n",
    "#validation_set = RawXXreverseDataset(args.validation_raw, args.validation_list, args.audio_window)\n",
    "train_loader = data.DataLoader(training_set, batch_size=args.batch_size, shuffle=True, **params) # set shuffle to True\n",
    "test_loader = data.DataLoader(test_set, batch_size=args.batch_size, shuffle=False, **params) # set shuffle to False\n",
    "# nanxin optimizer  \n",
    "optimizer = ScheduledOptim(\n",
    "    optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        betas=(0.9, 0.98), eps=1e-09, weight_decay=1e-4, amsgrad=True),\n",
    "    args.n_warmup_steps)\n",
    "\n",
    "model_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info('### Model summary below###\\n {}\\n'.format(str(model)))\n",
    "logger.info('===> Model total parameter: {}\\n'.format(model_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (2, 10, 16), got [1, 10, 16]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c763f7ef9747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#trainXXreverse(args, model, device, train_loader, optimizer, epoch, args.batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#val_acc, val_loss = validationXXreverse(args, model, device, validation_loader, args.batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-b0b511d0e2f3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, model, device, train_loader, optimizer, epoch, batch_size)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3545acbbd74f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m#     encode_samples[i-1] = z[:,t_samples+i,:].view(batch,512) # z_tk e.g. size 8*512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mforward_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# e.g. size 8*100*512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforward_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output size e.g. 8*100*256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mc_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# c_t e.g. size 8*256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# e.g. size 12*8*512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden size (2, 10, 16), got [1, 10, 16]"
     ]
    }
   ],
   "source": [
    "## Start training\n",
    "best_acc = 0\n",
    "best_loss = np.inf\n",
    "best_epoch = -1 \n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    epoch_timer = timer()\n",
    "\n",
    "    # Train and validate\n",
    "    #trainXXreverse(args, model, device, train_loader, optimizer, epoch, args.batch_size)\n",
    "    #val_acc, val_loss = validationXXreverse(args, model, device, validation_loader, args.batch_size)\n",
    "    train(args, model, device, train_loader, optimizer, epoch, args.batch_size)\n",
    "    val_acc, val_loss = validation(args, model, device, test_loader, args.batch_size)\n",
    "    \n",
    "    # Save\n",
    "    if val_acc > best_acc: \n",
    "        best_acc = max(val_acc, best_acc)\n",
    "        snapshot(args.logging_dir, run_name, {\n",
    "            'epoch': epoch + 1,\n",
    "            'validation_acc': val_acc, \n",
    "            'state_dict': model.state_dict(),\n",
    "            'validation_loss': val_loss,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        })\n",
    "        best_epoch = epoch + 1\n",
    "    elif epoch - best_epoch > 2:\n",
    "        optimizer.increase_delta()\n",
    "        best_epoch = epoch + 1\n",
    "    \n",
    "    end_epoch_timer = timer()\n",
    "    logger.info(\"#### End epoch {}/{}, elapsed time: {}\".format(epoch, args.epochs, end_epoch_timer - epoch_timer))\n",
    "\n",
    "## end \n",
    "end_global_timer = timer()\n",
    "logger.info(\"################## Success #########################\")\n",
    "logger.info(\"Total elapsed time: %s\" % (end_global_timer - global_timer))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cdc-2021-03-27_21_17_22'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}